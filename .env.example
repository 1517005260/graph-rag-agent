OPENAI_API_KEY = 'sk-xxx'
OPENAI_BASE_URL = 'http://localhost:13000/v1'

OPENAI_EMBEDDINGS_MODEL = 'text-embedding-3-large'
OPENAI_LLM_MODEL = 'gpt-4o'

TEMPERATURE = 0
MAX_TOKENS = 2000

# FastAPI 并发进程数
FASTAPI_WORKERS = 2

# 文本处理参数
CHUNK_SIZE = 500
CHUNK_OVERLAP = 100
MAX_TEXT_LENGTH = 500000
SIMILARITY_THRESHOLD = 0.9
RESPONSE_TYPE = '多个段落'

VERBOSE = True

# 并行与批处理设置
MAX_WORKERS = 4
BATCH_SIZE = 100
ENTITY_BATCH_SIZE = 50
CHUNK_BATCH_SIZE = 100
EMBEDDING_BATCH_SIZE = 64
LLM_BATCH_SIZE = 5
COMMUNITY_BATCH_SIZE = 50

# GDS 运行参数
GDS_MEMORY_LIMIT = 6
GDS_CONCURRENCY = 4
GDS_NODE_COUNT_LIMIT = 50000
GDS_TIMEOUT_SECONDS = 300

# 实体消歧配置
DISAMBIG_STRING_THRESHOLD = 0.7
DISAMBIG_VECTOR_THRESHOLD = 0.85
DISAMBIG_NIL_THRESHOLD = 0.6
DISAMBIG_TOP_K = 5
ALIGNMENT_CONFLICT_THRESHOLD = 0.5
ALIGNMENT_MIN_GROUP_SIZE = 2

NEO4J_URI='neo4j://localhost:7687'
NEO4J_USERNAME='neo4j'
NEO4J_PASSWORD='12345678'
NEO4J_MAX_POOL_SIZE = 10
NEO4J_REFRESH_SCHEMA = false

# 缓存向量相似度匹配配置
# 可选值: 'openai' (复用RAG的向量模型), 'sentence_transformer' (使用本地模型)
CACHE_EMBEDDING_PROVIDER = 'openai'
# 当使用sentence_transformer时的模型名，模型会缓存到 ./cache/model 目录
CACHE_SENTENCE_TRANSFORMER_MODEL = 'all-MiniLM-L6-v2'

# 模型缓存配置
MODEL_CACHE_ROOT = './cache'  # 缓存根目录，模型会保存到 {MODEL_CACHE_ROOT}/model
CACHE_ROOT = './cache'
CACHE_DIR = './cache'
CACHE_MEMORY_ONLY = false
CACHE_MAX_MEMORY_SIZE = 100
CACHE_MAX_DISK_SIZE = 1000
CACHE_THREAD_SAFE = true
CACHE_ENABLE_VECTOR_SIMILARITY = true
CACHE_SIMILARITY_THRESHOLD = 0.9
CACHE_MAX_VECTORS = 10000

# 相似实体检测设置
SIMILAR_ENTITY_WORD_EDIT_DISTANCE = 3
SIMILAR_ENTITY_BATCH_SIZE = 500
SIMILAR_ENTITY_MEMORY_LIMIT = 6
SIMILAR_ENTITY_TOP_K = 10

# 搜索工具参数
SEARCH_CACHE_MEMORY_SIZE = 200
SEARCH_VECTOR_LIMIT = 5
SEARCH_TEXT_LIMIT = 5
SEARCH_SEMANTIC_TOP_K = 5
SEARCH_RELEVANCE_TOP_K = 5
NAIVE_SEARCH_TOP_K = 3
LOCAL_SEARCH_TOP_CHUNKS = 3
LOCAL_SEARCH_TOP_COMMUNITIES = 3
LOCAL_SEARCH_TOP_OUTSIDE_RELS = 10
LOCAL_SEARCH_TOP_INSIDE_RELS = 10
LOCAL_SEARCH_TOP_ENTITIES = 10
LOCAL_SEARCH_INDEX_NAME = 'vector'
GLOBAL_SEARCH_LEVEL = 0
GLOBAL_SEARCH_BATCH_SIZE = 5
HYBRID_SEARCH_ENTITY_LIMIT = 15
HYBRID_SEARCH_MAX_HOP = 2
HYBRID_SEARCH_TOP_COMMUNITIES = 3
HYBRID_SEARCH_BATCH_SIZE = 10
HYBRID_SEARCH_COMMUNITY_LEVEL = 0

# Server 运行参数
SERVER_HOST = '0.0.0.0'
SERVER_PORT = 8000
SERVER_RELOAD = false
SERVER_LOG_LEVEL = 'info'
SERVER_WORKERS = 2  # 不设置时默认继承 FASTAPI_WORKERS

# 前端运行参数
FRONTEND_API_URL = 'http://localhost:8000'
FRONTEND_DEFAULT_AGENT = 'naive_rag_agent'
FRONTEND_DEFAULT_DEBUG = false
FRONTEND_SHOW_THINKING = true
FRONTEND_USE_DEEPER_TOOL = true
FRONTEND_USE_STREAM = true
FRONTEND_USE_CHAIN_EXPLORATION = true

# 知识图谱可视化参数
KG_PHYSICS_ENABLED = true
KG_NODE_SIZE = 25
KG_EDGE_WIDTH = 2
KG_SPRING_LENGTH = 150
KG_GRAVITY = -5000

# Agent 参数
AGENT_RECURSION_LIMIT = 5
AGENT_CHUNK_SIZE = 4
AGENT_STREAM_FLUSH_THRESHOLD = 40
DEEP_AGENT_STREAM_FLUSH_THRESHOLD = 80
FUSION_AGENT_STREAM_FLUSH_THRESHOLD = 60

# langsmith监控大模型配置，不需要可以不写
LANGSMITH_TRACING=true
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
LANGSMITH_API_KEY="xxx"
LANGSMITH_PROJECT="xxx"
