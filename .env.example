# === OpenAI 相关 ===
# OpenAI API 密钥
OPENAI_API_KEY = 'sk-xxx'
# OpenAI 兼容服务地址（可指向代理或本地兼容服务）
OPENAI_BASE_URL = 'http://localhost:13000/v1'

# 向量模型名称（用于文本嵌入检索）
OPENAI_EMBEDDINGS_MODEL = 'text-embedding-3-large'
# 生成模型名称（用于回答生成）
OPENAI_LLM_MODEL = 'gpt-4o'
# 视觉模型名称（用于图片理解）
OPENAI_VISION_MODEL = 'gpt-4o'

# OpenAI Vision 图片处理参数
# 单次处理的最大图片数量
VISION_MAX_IMAGE_COUNT = 3
# 图片缩放后的最大尺寸，格式为 "宽,高"
VISION_IMAGE_MAX_SIZE = '1024,1024'
# 图片压缩质量（仅对 JPEG 生效，1-100）
VISION_IMAGE_QUALITY = 85
# Vision API 图片细节级别：low / high / auto
VISION_IMAGE_DETAIL = 'high'

# 采样温度：越高越随机，建议 0~1
TEMPERATURE = 0
# 生成回答的最大 Token 限制
MAX_TOKENS = 2000

# === 文档解析与 MinerU 集成 ===
# 文档处理策略：legacy（原有切块方案）或 mineru（高级多模态解析）
DOCUMENT_PROCESSOR_MODE = 'legacy'

# MinerU API 服务连接配置（DocumentProcessor 与其他组件复用）
MINERU_API_URL = 'http://localhost:8899'
# 服务器连接超时配置
MINERU_API_TIMEOUT = 300

# MinerU 服务器运行参数（仅在本地运行 mineru_server.py 时需要）
MINERU_HOST = '0.0.0.0'
MINERU_PORT = 8899
MINERU_WORKERS = 1

# MinerU 项目路径与输出目录（默认指向当前仓库同级目录下的 MinerU 项目）
MINERU_HOME = '../MinerU'
MINERU_OUTPUT_DIR = './mineru_outputs'
MINERU_TEMP_DIR = './.tmp/mineru_temp'
# MinerU 静态资源对外访问地址，默认复用 MinerU API 的 /download 接口
MINERU_ASSET_BASE_URL = 'http://localhost:8899/download'
# MinerU 解析结果缓存注册表（默认存放于 cache/mineru_registry.json）
MINERU_CACHE_REGISTRY = './cache/mineru_registry.json'
# MinerU 模型下载来源：huggingface / modelscope / local
MINERU_MODEL_SOURCE = 'modelscope'

# MinerU 默认解析配置，其他配置可见MinerU/docs/
MINERU_DEFAULT_BACKEND = 'pipeline'
MINERU_DEFAULT_PARSE_METHOD = 'auto'
MINERU_DEFAULT_LANG = 'ch'
MINERU_FORMULA_ENABLE = true
MINERU_TABLE_ENABLE = true

# MinerU 输出开关
MINERU_DUMP_MD = true
MINERU_DUMP_CONTENT_LIST = true
MINERU_DUMP_MIDDLE_JSON = false
MINERU_DUMP_MODEL_OUTPUT = false

# MinerU 设备配置
MINERU_DEVICE_MODE = 'auto'

# === 服务并发 ===
# FastAPI 进程数（影响 API 并发能力）
FASTAPI_WORKERS = 2

# === 文本切分与基础 RAG ===
# 图谱冲突处理策略：manual_first / auto_first / merge
GRAPH_CONFLICT_STRATEGY = 'manual_first'
# 社区检测算法：leiden / sllpa
GRAPH_COMMUNITY_ALGORITHM = 'leiden'
# 文本分块大小（字符数）
CHUNK_SIZE = 500
# 分块重叠长度（字符数），用于保持上下文连续性
CHUNK_OVERLAP = 100
# 单篇文档允许的最大字符数
MAX_TEXT_LENGTH = 500000
# 相似度阈值（0~1），用于过滤向量检索结果
SIMILARITY_THRESHOLD = 0.9
# 默认回答格式（中文提示，示例：多个段落、表格等）
RESPONSE_TYPE = '多个段落'

# 是否输出更详细的调试日志
VERBOSE = True

# === 批处理与线程池 ===
# 全局最大线程数
MAX_WORKERS = 4
# 多智能体执行模式：sequential（串行）或 parallel（并行）
MA_WORKER_EXECUTION_MODE = 'sequential'
# 并行模式下的最大并发任务数
MA_WORKER_MAX_CONCURRENCY = 4
# 通用批处理大小
BATCH_SIZE = 100
# 实体批量操作大小
ENTITY_BATCH_SIZE = 50
# 文本块批量操作大小
CHUNK_BATCH_SIZE = 100
# 向量嵌入批处理大小
EMBEDDING_BATCH_SIZE = 64
# LLM 批量请求大小
LLM_BATCH_SIZE = 5
# 社区（图算法）批量处理大小
COMMUNITY_BATCH_SIZE = 50

# === Neo4j Graph Data Science (GDS) 参数 ===
# GDS 使用的内存上限（GB）
GDS_MEMORY_LIMIT = 6
# GDS 并发度
GDS_CONCURRENCY = 4
# GDS 数据规模限制（节点数）
GDS_NODE_COUNT_LIMIT = 50000
# GDS 算法超时时间（秒）
GDS_TIMEOUT_SECONDS = 300

# === 实体消歧/对齐 ===
# 文本编辑距离阈值（0~1，越小越严格）
DISAMBIG_STRING_THRESHOLD = 0.7
# 向量相似度阈值
DISAMBIG_VECTOR_THRESHOLD = 0.85
# 判定为未知（NIL）的阈值
DISAMBIG_NIL_THRESHOLD = 0.6
# 候选实体数量
DISAMBIG_TOP_K = 5
# 对齐冲突阈值
ALIGNMENT_CONFLICT_THRESHOLD = 0.5
# 对齐最小分组大小
ALIGNMENT_MIN_GROUP_SIZE = 2

# === Neo4j 连接信息 ===
# Neo4j 地址
NEO4J_URI='neo4j://localhost:7687'
# Neo4j 用户名
NEO4J_USERNAME='neo4j'
# Neo4j 密码
NEO4J_PASSWORD='12345678'
# 最大连接池大小
NEO4J_MAX_POOL_SIZE = 10
# 是否在启动时刷新 Schema
NEO4J_REFRESH_SCHEMA = false

# === 缓存（Cache Manager） ===
# 向量匹配提供者：openai / sentence_transformer
CACHE_EMBEDDING_PROVIDER = 'openai'
# 当使用本地模型时的模型名称
CACHE_SENTENCE_TRANSFORMER_MODEL = 'all-MiniLM-L6-v2'

# 模型与结果缓存目录
MODEL_CACHE_ROOT = './cache'
CACHE_ROOT = './cache'
CACHE_DIR = './cache'
# 预加载的本地 SentenceTransformer 模型列表（逗号分隔）
SENTENCE_TRANSFORMER_MODELS = ''
# TikToken 缓存目录
TIKTOKEN_CACHE_DIR = './cache/tiktoken'
# 是否只使用内存缓存
CACHE_MEMORY_ONLY = false
# 内存缓存最大容量（MB）
CACHE_MAX_MEMORY_SIZE = 100
# 磁盘缓存最大容量（MB）
CACHE_MAX_DISK_SIZE = 1000
# 是否启用线程安全
CACHE_THREAD_SAFE = true
# 是否启用向量相似度缓存
CACHE_ENABLE_VECTOR_SIMILARITY = true
# 缓存判定相似度阈值
CACHE_SIMILARITY_THRESHOLD = 0.9
# 缓存向量数量上限
CACHE_MAX_VECTORS = 10000

# === 相似实体检测 ===
# 允许的最大编辑距离
SIMILAR_ENTITY_WORD_EDIT_DISTANCE = 3
# 检测批处理大小
SIMILAR_ENTITY_BATCH_SIZE = 500
# 运行所需的内存上限（GB）
SIMILAR_ENTITY_MEMORY_LIMIT = 6
# 返回的候选实体数量
SIMILAR_ENTITY_TOP_K = 10

# === 检索工具参数 ===
# 检索缓存占用的内存上限（MB）
SEARCH_CACHE_MEMORY_SIZE = 200
# 向量检索返回数量
SEARCH_VECTOR_LIMIT = 5
# 文本检索返回数量
SEARCH_TEXT_LIMIT = 5
# 语义检索 Top K
SEARCH_SEMANTIC_TOP_K = 5
# 关键词检索 Top K
SEARCH_RELEVANCE_TOP_K = 5
# 朴素检索返回条数
NAIVE_SEARCH_TOP_K = 3
# 朴素检索的候选集大小限制（为 0 或负数时不限制）
NAIVE_SEARCH_CANDIDATE_LIMIT = 2000
# 本地检索返回的文本块数量
LOCAL_SEARCH_TOP_CHUNKS = 3
# 本地检索返回的社区数量
LOCAL_SEARCH_TOP_COMMUNITIES = 3
# 图外关系检索数量
LOCAL_SEARCH_TOP_OUTSIDE_RELS = 10
# 图内关系检索数量
LOCAL_SEARCH_TOP_INSIDE_RELS = 10
# 返回的相关实体数量
LOCAL_SEARCH_TOP_ENTITIES = 10
# Neo4j 向量索引名称
LOCAL_SEARCH_INDEX_NAME = 'vector'
# 全局搜索默认层级
GLOBAL_SEARCH_LEVEL = 0
# 全局搜索批大小
GLOBAL_SEARCH_BATCH_SIZE = 5
# 全局搜索社区附带的多模态chunk数量
GLOBAL_SEARCH_CHUNK_LIMIT = 5
# 混合检索实体数量上限
HYBRID_SEARCH_ENTITY_LIMIT = 15
# 混合检索图探索最大跳数
HYBRID_SEARCH_MAX_HOP = 2
# 混合检索社区数量
HYBRID_SEARCH_TOP_COMMUNITIES = 3
# 混合检索批大小
HYBRID_SEARCH_BATCH_SIZE = 10
# 混合检索的社区层级
HYBRID_SEARCH_COMMUNITY_LEVEL = 0

# === 服务端运行 ===
# 监听地址
SERVER_HOST = '0.0.0.0'
# 监听端口
SERVER_PORT = 8000
# 是否热重载
SERVER_RELOAD = false
# 日志级别
SERVER_LOG_LEVEL = 'info'
# 工作进程数（优先于 FASTAPI_WORKERS）
SERVER_WORKERS = 2

# === 前端默认配置 ===
# API 网关地址
FRONTEND_API_URL = 'http://localhost:8000'
# 默认使用的 Agent 名称
FRONTEND_DEFAULT_AGENT = 'naive_rag_agent'
# 是否默认开启调试面板
FRONTEND_DEFAULT_DEBUG = false
# 是否展示思维链
FRONTEND_SHOW_THINKING = true
# 是否允许深度研究工具
FRONTEND_USE_DEEPER_TOOL = true
# 是否启用流式输出
FRONTEND_USE_STREAM = true
# 是否允许链式探索工具
FRONTEND_USE_CHAIN_EXPLORATION = true

# === 图谱可视化（前端）===
# 是否启用物理模拟
KG_PHYSICS_ENABLED = true
# 节点默认大小
KG_NODE_SIZE = 25
# 边线宽
KG_EDGE_WIDTH = 2
# 弹簧长度（节点间距）
KG_SPRING_LENGTH = 150
# 引力系数（负数表示斥力）
KG_GRAVITY = -5000

# === Agent 调度相关 ===
# 最大递归深度（LangGraph）
AGENT_RECURSION_LIMIT = 5
# 单批次传入 LangGraph 的消息碎片数
AGENT_CHUNK_SIZE = 4
# 普通 Agent 的流式 flush 阈值（字符数）
AGENT_STREAM_FLUSH_THRESHOLD = 40
# DeepResearch Agent 的流式 flush 阈值
DEEP_AGENT_STREAM_FLUSH_THRESHOLD = 80
# Fusion Agent 的流式 flush 阈值
FUSION_AGENT_STREAM_FLUSH_THRESHOLD = 60

# === 多智能体编排 ===
# 单次 Planner 允许生成的最大任务数
MA_PLANNER_MAX_TASKS = 6
# 是否允许在澄清未完成时继续执行
MA_ALLOW_UNCLARIFIED_PLAN = true
# 默认任务领域标签
MA_DEFAULT_DOMAIN = '通用'
# 执行结束后是否自动生成报告
MA_AUTO_GENERATE_REPORT = true
# 如果需要用户澄清是否立即停止执行
MA_STOP_ON_CLARIFICATION = true
# Planner 未返回执行信号时是否视为失败
MA_STRICT_PLAN_SIGNAL = true
# 默认报告类型（short_answer / long_document）
MA_DEFAULT_REPORT_TYPE = 'long_document'
# 是否启用一致性检查
MA_ENABLE_CONSISTENCY_CHECK = true
# 是否开启 Map-Reduce 写作模式
MA_ENABLE_MAPREDUCE = true
# 触发 Map-Reduce 的证据条数阈值
MA_MAPREDUCE_THRESHOLD = 20
# Reduce 阶段每次允许的最大 Token 预算
MA_MAX_TOKENS_PER_REDUCE = 4000
# Map 阶段是否并行调用
MA_ENABLE_PARALLEL_MAP = true
# 单个章节写作允许的证据数量
MA_SECTION_MAX_EVIDENCE = 8
# 多批写作时保留的前文上下文长度
MA_SECTION_MAX_CONTEXT_CHARS = 800
# 反思阶段是否允许自动重试
MA_REFLECTION_ALLOW_RETRY = false
# 单个目标任务允许的反思重试次数
MA_REFLECTION_MAX_RETRIES = 1

# === Langsmith 监控（可选）===
# 是否启用 Langsmith Tracing
LANGSMITH_TRACING=true
# Langsmith 服务地址
LANGSMITH_ENDPOINT="https://api.smith.langchain.com"
# Langsmith API Key
LANGSMITH_API_KEY="xxx"
# Langsmith 项目名称
LANGSMITH_PROJECT="xxx"
